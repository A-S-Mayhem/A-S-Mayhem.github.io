---
layout: archive
title: "Resume"
permalink: /resume/
author_profile: true
redirect_from:
  - /resume
  - /cv
---

{% include base_path %}
[Download PDF](https://docs.google.com/document/d/12nh3AOX7vRsxJB9Tl3vcPk3FuHFIepbvyMkYmbL8xis/edit?usp=sharing)

Education
======
* **B.S. in Industrial & Systems Engineering, The Ohio State University**, 2019

Work experience
======
* **Data & Analytics Consultant**, CapTech Ventures Inc.			                  
  * Columbus, Ohio, Jan. 2020 - Present
  * **Software Developer - Python**, Fortune 200 Used Car Retailer
    * Performed infrastructure systems integration and deployment in Microsoft Azure, using Ansible (Python) and TeamCity.
  * **Big Data / Machine Learning Engineer**, Fortune 100 Financial Services Company
    * Played a critical role on a team of data scientists to develop a risk modeling score using a dynamic penalty function to grade each business application by cyber risk by summarizing over 170 metrics across 4 domains.
    * Formulated a penalty function, worked with subject matter experts (SMEs) to own the “Resiliency” domain within cyber risk, and developed and productionized the model in Python and SQL on AWS.


* **Data Science Implementation Specialist Intern**, Nationwide Insurance
  * Columbus, Ohio, May 2019 - Dec. 2019
  * Developed and deployed a performance monitoring system for all predictive models in the Predictive Analytics Department so both audit and data science leadership can understand how models change over time.
  * Handled all ETL processes in SQL and SPSS Modeler. Used Python and Django to visualize data in a web application. 
  * Prepared and deployed other predictive models into production with IBM’s SPSS Collaboration and Deployment Services.
  * Environment:  Teradata, Linux, Django, Python, R, Shell, Tableau, Postgre SQL Server.


* **Data Science Capstone Project**, NetJets						   
  * Columbus, Ohio, Aug. 2019 - Dec. 2019
  * Lead a group of three to develop a predictive model to estimate the probability of an unscheduled maintenance event occurring on a specific jet the next day, based on 2019 YTD data.
  * Challenges included relating maintenance events to recent flights (no join keys) and imbalanced dataset.
  * Concluded with a random forest model with a Type I (overly conservative) error rate of ~40% and Type II error rate of 2-5%.  The models applied to 47% of the fleet and a conservative 1% reduction in total unexpected maintenance events translates to $1.7 million in savings YoY.


* **Big Data Engineer Intern**, Vertiv Co.						          
  * Central Ohio, May 2018 - Oct. 2018
  * Gained extensive understanding of big data technologies and framework as well as coding experience in Python and SQL.  
  * Created the framework to automatically ingest and cleanse marketing data streams from various web APIs to the company’s data lake, though various layers of processing, and ultimately in updated views inside of Power BI for analytics. 
  * Automated data entry jobs using Python and VBA, saving the company over 100 hours per month.
  * Environment: Hadoop, HDFS, Cloudera Data Science Workbench, Linux, Talend, Kafka, Power BI.


Skills
======
* **Programming Languages**: Python (Pandas, NumPy, Scikit-Learn, PySpark, PyTorch), SQL, R, Linux, Bash
* **Software**: Tableau, QuickSight, Power BI, SPSS Modeler
* **Databases**: Snowflake, Hive, Teradata, SQLite, PostgreSQL Server, MS Access, AWS Redshift
* Lean Six Sigma Yellow Belt Certified
