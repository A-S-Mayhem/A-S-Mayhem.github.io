---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---

{% if author.googlescholar %}
  You can also find my articles on <u><a href="{{author.googlescholar}}">my Google Scholar profile</a>.</u>
{% endif %}

{% include base_path %}

<!--THESIS-->
<div>
  <h2>Representation Learning for Data-Efficient Reinforcement Learning</h2>
</div>
<!--<div>-->
  <!--<img src="{{ base_path }}/images/cheetah-run.gif" border="100" style="margin: 1em 1em 1em 0em; width: 10%; height: auto;"/>-->
  <!--<p>Development of $k$-Step Latent, a novel representation learning routine for reinfrocement learning that provides state-of-the-art results in the populat PlaNet benchmark suite.</p>-->
<!--</div>-->
<div style="width:100%; height:auto; padding:1%;">
  <div>
    <img src="{{ base_path }}/images/cheetah-run.gif" border="100" style="margin: 0em 0em 0em 0em; width: 18%; height: auto; float:left;"/>
  </div>
  <div style="margin-left:190px;">
    <p>Development of $k$-Step Latent (KSL), a novel representation learning routine for reinfrocement learning that provides state-of-the-art results in the populat PlaNet benchmark suite.
    KSL's representation learning module consists of several sub-networks with momentum counterparts (similar to BYOL), as well as a recurrent operation that encourages temporally coherent representations <i>in the latent space</i>.
    </p>
  </div>
</div>
<div style="text-align:center;">
  <p>
    <!--<a href="https://arxiv.org/abs/2103.06398v1">[PAPER]</a>-->
    [PAPER IN REVIEW]
    &nbsp; &nbsp; &nbsp; &nbsp;
    <a href="https://github.com/trevormcinroe/thesis">[CODE]</a>
  </p>
</div>

<br>

<!--ANALYZING HIDDEN ACTIVATIONS-->
<div>
  <h2>Analyzing the Hidden Activations of Deep Policy Networks: Why Representation Matters</h2>
</div>
<div style="width:100%; height:auto; padding:1%;">
  <div>
    <img src="{{ base_path }}/images/analyzing_z.png" border="100" style="margin: 0em 0em 0em 0em; width: 18%; height: auto; float:left;"/>
  </div>
  <div style="margin-left:190px;">
    <p>Summary of work.</p>
  </div>
</div>

<div style="text-align:center;">
  <p>
    <a href="https://arxiv.org/abs/2103.06398v1">[PAPER]</a>
    &nbsp; &nbsp; &nbsp; &nbsp;
    <a href="https://github.com/trevormcinroe/rl_with_latents">[CODE]</a>
  </p>
</div>

<br>

<!--REMOVING RAIN-->
<div>
  <h2>Removing Rain from Images with Densely-Connected Convolutional Networks</h2>
</div>
<div style="width:100%; height:auto; padding:1%;">
  <div>
    <img src="{{ base_path }}/images/derain_drn.png" border="100" style="margin: 0em 0em 0em -1.5em; width: 20%; height:auto; float:left;"/>
  </div>
  <div style="margin-left:190px;">
    <p>Summary of work.</p>
  </div>
</div>

<div style="text-align:center;">
  <p>
    <a href="https://toyota-connected-assets.s3.us-east-2.amazonaws.com/pdf/mcinroe_deraining_case_study_final.pdf">[PAPER]</a>
    &nbsp; &nbsp; &nbsp; &nbsp;
    [CODE NOT PUBLIC]
  </p>
</div>

<!--IRL-->
<div>
  <h2>Creating Web Ads with Inverse Reinforcement Learning</h2>
</div>
<div style="width:100%; height:auto; padding:1%;">
  <div>
    <img src="{{ base_path }}/images/derain_drn.png" border="100" style="margin: 0em 0em 0em -2em; width: 20%; height: auto; float:left;"/>
  </div>
  <div style="margin-left:190px;">
    <p>Summary of work.</p>
  </div>
</div>

<div style="text-align:center;">
  <p>
    [PAPER NOT PUBLIC]
    &nbsp; &nbsp; &nbsp; &nbsp;
    [CODE NOT PUBLIC]
  </p>
</div>

