---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<!---
<p align="center">
  <img src="https://github.com/peterbhase/peterbhase.github.io/blob/master/images/s2.jpg?raw=True" alt="Photo" style="width: 300px;"/> 
</p>
-->

## About Me

I am a second-year PhD student in the [MURGe-Lab](https://murgelab.cs.unc.edu/) at the University of North Carolina at Chapel Hill, where I am advised by [Mohit Bansal](http://www.cs.unc.edu/~mbansal/). My work at UNC is supported by a [Royster Fellowship](https://gradschool.unc.edu/funding/gradschool/royster/membership.html). Before this, I graduated with a bachelor's degree from Duke University, where my thesis advisor was [Cynthia Rudin](https://users.cs.duke.edu/~cynthia/). At Duke I was supported by a [Trinity Scholarship](https://www.ousf.duke.edu/page/Trin). 

My research interests center on interpretable machine learning and natural language processing. I am particularly interested in techniques for explaining model behavior and aligning ML systems with human values, which are problems I see natural language playing a prominent role in. I am broadly interested in topics related to AI Safety. In all of these areas, I find work on clarifying concepts and developing strong evaluation procedures especially valuable. 

*Email:* peter@cs.unc.edu

## News
* 2021 - New preprint on arxiv: "When Can Models Learn From Explanations? A Formal Framework for Understanding the Roles of Explanation Data" [[pdf]](https://arxiv.org/abs/2102.02201) [[code]](https://github.com/peterbhase/ExplanationRoles)
* 2020 - New preprint on arxiv! "FastIF: Scalable Influence Functions for Efficient Model Interpretation and Debugging" [[pdf]](https://arxiv.org/abs/2012.15781) [[code]](https://github.com/salesforce/fast-influence-functions)
* 2020 - Recognized as an [Outstanding Reviewer](https://www.aclweb.org/anthology/2020.emnlp-main.0.pdf#page=29) for EMNLP 2020
* 2020 - Paper accepted into [Findings of EMNLP](https://2020.emnlp.org/), "Leakage-Adjusted Simulatability: Can Models Generate Non-Trivial Explanations of Their Behavior in Natural Language?" [[pdf]](https://arxiv.org/abs/2010.04119) [[code]](https://github.com/peterbhase/LAS-NL-Explanations)
* 2020 - Paper accepted into [ACL 2020](https://acl2020.org/), "Evaluating Explainable AI: Which Algorithmic Explanations Help Users Predict Model Behavior?"  [[pdf]](https://arxiv.org/abs/2005.01831) [[code]](https://github.com/peterbhase/InterpretableNLP-ACL2020)
* 2019 - Paper accepted into [AAAI-HCOMP 2019](https://www.humancomputation.com/), "Interpretable Image Recognition with Hierarchical Prototypes" [[pdf]](https://arxiv.org/abs/1906.10651) [[code]](https://github.com/peterbhase/interpretable-image)
* 2019 - Joined the [UNC NLP](https://nlp.cs.unc.edu/) lab
* 2019 - Graduated with a B.S. from the Department of Statistical Science at Duke University
* 2019 - Awarded the [William R. Kenan Jr. (Royster) Fellowship](https://gradschool.unc.edu/funding/gradschool/royster/membership.html) from UNC Chapel Hill
* 2018 - Received First Prize in Darmouth's PoetiX Literary Turing Test (see submission [[pdf]](https://arxiv.org/abs/1811.05067) and [[code]](https://github.com/peterbhase/poetry-generation))
* 2018 - Nominated for Statistical Science Undergraduate TA of the Year

