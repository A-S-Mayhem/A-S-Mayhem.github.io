---
permalink: /
title: "About me"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I am Yusheng Su, a Ph.D. student in [THUNLP Lab](https://twitter.com/tsinghuanlp), the [Department of Computer Science and Technology](http://www.cs.tsinghua.edu.cn/) at [Tsinghua University](https://www.tsinghua.edu.cn/publish/thu2018en/index.html). I am advised by [Prof. Zhiyuan Liu](https://scholar.google.com/citations?user=dT0v5u0AAAAJ&hl=zh-TW). My research interests lie within the intersection of Natural Language Processing and Machine Learning. At the current stage, I am specifically interested in Pre-trained Language Models and Transfer Learning. <!--You can find my CV [here](/cv/).-->



## Coming Soon


Will share our work: [On Transferability of Prompt Tuning for Natural Language Processing](https://arxiv.org/abs/2111.06719) on NAACL.
<br>Time</br>: July 10, 2022, 10:45 â€“ 12:15 (UTC - 7:00)
<br>Place</br>: Elwha A, Hyatt Regency Seattle, Seattle, Washington, United States.  
<br>Session</br>: Efficient Methods in NLP


## News
* [Jul. 2022] Share our work [[pdf]](https://arxiv.org/abs/2111.06719) on NAACL Oral Session.
* [Apr. 2022] Got two papers accepted at NAACL 2022. 
* [Mar. 2022] Got one paper accepted at ACL 2022. 
* [Aug. 2021] Got one paper accepted at IEEE/TASLP 2021.
* [Feb. 2021] Got one paper accepted at WWW 2021.
* [Aug. 2020] Got one paper accepted at EMNLP 2020.

<!-- <font color="gray"> </font> -->


## Professional Services
* Program Committee Member: EMNLP 2022
* Reviewer: ICML 2022
* Reviewer: ACL Rolling 2022
* Reviewer: ACL Rolling 2021
* Reviewer: EMNLP/ACL/IEEE-TASLP 2021
<!-- * Program Committee Member: EMNLP 2021 -->
<!-- * Review Assistant: ACL 2021 -->




## Publications

* <b>Yusheng Su</b>, Xiaozhi Wang, Yujia Qin, Chi-Min Chan, Yankai Lin, Zhiyuan Liu, Peng Li, Juanzi Li, Lei Hou, Maosong Sun, Jie Zhou. <b>On Transferability of Prompt Tuning for Natural Language Processing</b> (NAACL 2022 <b>Oral</b>). [[pdf]](https://arxiv.org/abs/2111.06719) [[code]](https://github.com/thunlp/Prompt-Transferability)

* Yujia Qin, Yankai Lin, Jing Yi, Jiajie Zhang, Xu Han, Zhengyan Zhang, <b>Yusheng Su</b>, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou. <b>Knowledge Inheritance for Pre-trained Language Models</b> (NAACL 2022 <b>Oral</b>). [[pdf]](https://arxiv.org/abs/2105.13880) [[code]](https://github.com/thunlp/Knowledge-Inheritance)

* Yujia Qin, Xiaozhi Wang, <b>Yusheng Su</b>, Yankai Lin, Ning Ding, Zhiyuan Liu, Juanzi Li, Lei Hou, Peng Li, Maosong Sun, Jie Zhou. <b>Exploring Low-dimensional Intrinsic Task Subspace via Prompt Tuning</b> (ACL-Findings 2022). [[pdf]](https://arxiv.org/abs/2110.07867) [[code]](https://github.com/thunlp/Intrinsic-Prompt-Tuning)

* Zhengyan Zhang, Xu Han, Hao Zhou, Pei Ke, Yuxian Gu, Deming Ye, Yujia Qin, <b>Yusheng Su</b>, Haozhe Ji, Jian Guan, Fanchao Qi, Xiaozhi Wang, Yanan Zheng, Guoyang Zeng, Huanqi Cao, Shengqi Chen, Daixuan Li, Zhenbo Sun, Zhiyuan Liu, Minlie Huang, Wentao Han, Jie Tang, Juanzi Li, Xiaoyan Zhu, Maosong Sun. <b>CPM: A large-scale generative Chinese pre-trained language model</b> (AI OPEN 2021). [[pdf]](https://www.sciencedirect.com/science/article/pii/S266665102100019X) [[code]](https://github.com/TsinghuaAI/CPM)

* <b>Yusheng Su</b>, Xu Han, Yankai Lin, Zhengyan Zhang, Zhiyuan Liu, Peng Li, Maosong Sun. <b>CSS-LM: A Contrastive Framework for Semi-supervised Fine-tuning of Pre-trained Language Models</b> (WWW-workshop 2020, IEEE/TASLP 2021). [[pdf]](https://arxiv.org/abs/2102.03752) [[code]](https://github.com/thunlp/CSS-LM) 

* <b>Yusheng Su</b>, Xu Han, Zhengyan Zhang, Peng Li, Zhiyuan Liu, Yankai Lin, Jie Zhou, Maosong Sun. <b>CokeBERT: Contextual Knowledge Selection and Embedding towards Enhanced Pre-Trained Language Models</b> (EMNLP-Findings 2020, AI OPEN 2021). [[pdf]](https://arxiv.org/abs/2009.13964) [[pdf]](https://www.sciencedirect.com/science/article/pii/S2666651021000188) [[code]](https://github.com/thunlp/CokeBERT)




## Under Review or Preprint Version <!-- Submitted for Publications-->

* Ning Ding, Yujia Qin, Guang Yang, Fuchao Wei, Zonghan Yang, <b>Yusheng Su</b>, Shengding Hu, Yulin Chen, Chi-Min Chan, Weize Chen, Jing Yi, Weilin Zhao, Xiaozhi Wang, Zhiyuan Liu, Hai-Tao Zheng, Jianfei Chen, Yang Liu, Jie Tang, Juanzi Li, Maosong Sun. <b>Delta Tuning: A Comprehensive Study of Parameter Efficient Methods for Pre-trained Language Models</b> (ArXiv). [[pdf]](https://arxiv.org/abs/2203.06904)




## Research Experiences

### Tsinghua NLP Lab. (Beijing) 09.2019 - 07.2023
* Ph.D. Student 
* Advised by [Prof. Zhiyuan Liu](http://nlp.csai.tsinghua.edu.cn/~lzy/).

### MediaTek. (Taiwan) 07.2018 - 08.2019
* Deep/Machine Learning Engineer Intern
* Advised by Jing-Han Wang.

### Microsoft. (Taiwan) 07.2015 - 07.2016
* Research & Development Intern
* Advised by [Kuang-Chao Yeh](https://www.linkedin.com/in/kuang-chao-yeh/) and [Gordon Chang](https://www.linkedin.com/in/gordonwinnow).
