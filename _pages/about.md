---
permalink: /
title: "Bio"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

<p style="text-align:justify; text-justify:inter-ideograph;">
Shaolei Zhang is currently working toward his Ph.D. degree in the Key Laboratory of Intelligent Information Processing, Institute of Computing Technology, Chinese Academy of Sciences (ICT/CAS). He received his bachelor's degree from Beijing University of Posts and Telecommunications in 2020, majoring in computer science and technology. His research interests include nature language processing, machine translation and simultaneous translation. He has published 11 papers on the international conferences, and won the first place in the streaming transcription track of AutoSimTrans 2021.
</p>

------

News
======

- [2023.01.21]	<font color=red>One paper</font> is accepted by ICLR 2023 (spotlight).
- [2022.10.06]	<font color=red>Three papers</font> are accepted by EMNLP 2022.
- [2022.02.24]	<font color=red>Three papers</font> are accepted by ACL 2022.

------

Publications
======
- **Shaolei Zhang**, Yang Feng. Information-Transport-based Policy for Simultaneous Translation. *EMNLP 2022*. [[PDF](https://arxiv.org/pdf/2210.12357.pdf)] [[Code](https://github.com/ictnlp/ITST)]
- **Shaolei Zhang**, Shoutao Guo, Yang Feng. Wait-info Policy: Balancing Source and Target at Information Level for Simultaneous Machine Translation. *EMNLP 2022 findings*. [[PDF](https://arxiv.org/pdf/2210.11220.pdf)] [[Code](https://github.com/ictnlp/Wait-info)]
- Shoutao Guo, **Shaolei Zhang**, Yang Feng. Turning Fixed to Adaptive: Integrating Post-Evaluation into Simultaneous Machine Translation. *EMNLP 2022 findings*. [[PDF](https://arxiv.org/pdf/2210.11900.pdf)] [[Code](https://github.com/ictnlp/PED-SiMT)]
- **Shaolei Zhang**, Yang Feng. Modeling Dual Read/Write Paths for Simultaneous Machine Translation. *ACL 2022*. [[PDF](https://aclanthology.org/2022.acl-long.176.pdf)] [[Code](https://github.com/ictnlp/Dual-Path)]
- **Shaolei Zhang**, Yang Feng. Reducing Position Bias in Simultaneous Machine Translation with Length-Aware Framework. *ACL 2022*. [[PDF](https://aclanthology.org/2022.acl-long.467.pdf)]
- **Shaolei Zhang**, Yang Feng. Gaussian Multi-head Attention for Simultaneous Machine Translation. *ACL 2022 findings*. [[PDF](https://aclanthology.org/2022.findings-acl.238.pdf)] [[Code](https://github.com/ictnlp/GMA)]
- **Shaolei Zhang**, Yang Feng. Universal Simultaneous Machine Translation with Mixture-of-Experts Wait-k Policy. *EMNLP 2021*. [[PDF](https://aclanthology.org/2021.emnlp-main.581.pdf)] [[Code](https://github.com/ictnlp/MoE-Waitk)]
- **Shaolei Zhang**, Yang Feng. Modeling Concentrated Cross-Attention for Neural Machine Translation with Gaussian Mixture Model. *EMNLP 2021 findings*. [[PDF](https://aclanthology.org/2021.findings-emnlp.121.pdf)] 
- **Shaolei Zhang**, Yang Feng. ICT’s System for AutoSimTrans 2021: Robust Char-Level Simultaneous Translation. *AutoSimTrans@NAACL 2021*. [[PDF](https://aclanthology.org/2021.autosimtrans-1.1.pdf)]
- **Shaolei Zhang**, Yang Feng, Liangyou Li. Future-Guided Incremental Transformer for Simultaneous Translation. *AAAI 2021*. [[PDF](https://arxiv.org/pdf/2012.12465.pdf)]
- **Shaolei Zhang**, Gang Lu, Kai Shuang. Opinion Knowledge Injection Network for Aspect Extraction. *ICONIP 2019*. [[PDF](https://link.springer.com/chapter/10.1007/978-3-030-36711-4_56)]

------

Award
======
- [2022]	National scholarship (国家奖学金)
- [2021]	First place in the streaming transcription track of AutoSimTrans 2021
- [2020]	Beijing outstanding graduate (北京市优秀毕业生)
- [2018]	Beijing merit student (北京市三好学生)
- [2017]	National scholarship (国家奖学金)
