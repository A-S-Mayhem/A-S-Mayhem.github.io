---
title: "Patch-adaptive Transformation Blending for One-shot Photo Retouching"
excerpt: "<img src='/images/teaser_cropped-1.png'>"

collection: projects
---
<!DOCTYPE html>
<html><head lang="en"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    
    <meta http-equiv="x-ua-compatible" content="ie=edge">

    <title>Ref-NeRF</title>

    <meta name="description" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <meta property="og:image" content="https://dorverbin.github.io/refnerf/img/refnerf_titlecard.jpg">
    <meta property="og:image:type" content="image/png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://dorverbin.github.io/refnerf">
    <meta property="og:title" content="Patch-adaptive Transformation Blending for One-shot Photo Retouching">
    <meta property="og:description" content="Photographers often put considerable effort into generating high-quality retouched photos with elaborate details. Retouching edits comprise a series of global adjustments and more intricate local edits, e.g., with a brush or local filters. Such edits adjust particular features, such as brightness, contrast, or texture statistics, of specific regions with similar characteristics. Photo retouching is, in general, a difficult task for novice users
as it requires expert knowledge and advanced tools. In this
paper, we introduce a learning-based technique to automatically
retouch details of an input image based on a single pair of
before and after example images. Our technique can provide
detailed retouches without manual effort or a large dataset by
learning a different map per frequency level. By decomposing
before and after images into different frequency levels based
on multiscale image analysis, we achieve a higher expressive
power of the model. To further increase the capacity of our
model, we blend multiple trainable transformation matrices with
corresponding weights defined by a multilayer perceptron (MLP)
block. Previous work shows that instead of predicting an edited
image directly from an input image, learning a transformation
is, in general, more efficient and easier. Therefore, our technique
learns transformation matrices and computes their weighted sum
to define maps. Since the weights are patch-adaptive thanks to the
MLP block, our map representation becomes spatially varying,
hence captures retouching edits even in complex details.">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Ref-NeRF: Structured View-Dependent Appearance for Neural Radiance Fields">
    <meta name="twitter:description" content="Neural Radiance Fields (NeRF) is a popular view synthesis technique that represents a scene as a continuous volumetric function, parameterized by multilayer perceptrons that provide the volume density and view-dependent emitted radiance at each location. While NeRF-based techniques excel at representing fine geometric structures with smoothly varying view-dependent appearance, they often fail to accurately capture and reproduce the appearance of glossy surfaces. We address this limitation by introducing Ref-NeRF, which replaces NeRF's parameterization of view-dependent outgoing radiance with a representation of reflected radiance and structures this function using a collection of spatially-varying scene properties. We show that together with a regularizer on normal vectors, our model significantly improves the realism and accuracy of specular reflections. Furthermore, we show that our model's internal representation of outgoing radiance is interpretable and useful for scene editing.">
    <meta name="twitter:image" content="https://dorverbin.github.io/refnerf/img/refnerf_titlecard.jpg">


</head>
  
<script
  defer
  src="https://unpkg.com/img-comparison-slider@7/dist/index.js"
></script>
<link
  rel="stylesheet"
  href="https://unpkg.com/img-comparison-slider@7/dist/styles.css"
/>

<img-comparison-slider>
  <img slot="first" src="/images/17926.png" width="400" height="500" />
  <img slot="second" src="/images/PT_makeup2_test5_256_with_var.png" width="400" height="500" />
</img-comparison-slider>


<img-comparison-slider>
  <img slot="first" src="/images/17603.png" width="400" height="500" />
  <img slot="second" src="/images/PT_teaser_test4_256_with_var.png" width="400" height="500" />
</img-comparison-slider>
