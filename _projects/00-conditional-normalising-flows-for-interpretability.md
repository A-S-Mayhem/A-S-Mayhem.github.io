---
title: "Master Thesis: Conditional Normalising Flows for Interpretability"
link: 'https://github.com/gcskoenig/rfi'
excerpt: "![thesis](/images/thesis.png){: style='float: left; width:380px'} This work aims to fill the gap of two existing interpretability methods for global feature importance (Relative feature importance and Shapley additive global importance), by using deep conditional density estimator/sampler â€“ **Conditional Normalising Flow**. After utilising noise regularisation, they do not require a rigorous hyperparameter search and could be used in the vanilla setting. We make an extensive empirical evaluation on different synthetic and real datasets with the help of a self-designed evaluation benchmark. Ground-truth feature importances are in general intractable, thus we inherited the concepts of strong and weak feature relevance, which have one-to-one relation to the causal structure of data generating mechanism. By utilising continuous datasets with a known causal graph, we can reason about the validity of estimated importances. Additionally, we provided a use case of RFI for detection of influence of sensitive attributes, when they are included in predictive modelling or completely ignored. This thesis extends the existing Python library for [Relative Feature Importance](https://github.com/gcskoenig/rfi), with Conditional Normalising Flow and Mixture Density Network, as well as with the synthetic benchmark."
---
