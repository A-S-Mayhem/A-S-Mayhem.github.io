{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Lab2a.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"2Nb6W-P3DvSQ"},"source":["# LAB 2: BASIC INTRO TO PYTHON AND WEB-SCRAPING"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"sK4uIobBF4yH"},"source":["## Part 1. Basic Intro to Python\n","We will use Python to collect data, but use R to tidy data. In the last week's Tutorial, we covered how to install Python/Spyder. You should be Python-ready. You can open the our tutorial using jupyter notebook or google colab. \n","\n","If your system does not have jupyter notebook, pls check here for more information about how to install jupyter notebook <https://jupyter.org/install>.\n","\n","If your sytem has pip, you can simply run the following code in your terminal (note that ! indicates running in terminal):\n"]},{"cell_type":"code","metadata":{"id":"b6lNx3CVo5Er","colab_type":"code","colab":{}},"source":["!pip install notebook\n","!jupyter notebook"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"reMygVb4Glh8"},"source":["**If you system does not install pip, you can check here for more details:https://pip.pypa.io/en/stable/installing/**\n","\n","Similarly, you can install modules like pandas, numpy, selenium,bs4 (beautifulsoup), tensorflow, pytorch, keras, etc.\n","\n","We are not going to cover those Python Basics today. You can read **NLP with Python** Chapters1-3 for more details <https://www.nltk.org/book/>. Next Week, we will briefly cover those basics when we learn topic modeling. \n","\n","Today, we only introduce some basics related to webscraping. "]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Yu2kD_KkG-Lp"},"source":["### 1. Play with your working directory and then open and save files"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zml-2ypCHFtG","colab":{}},"source":["# get current working directory\n","import os\n","path=os.getcwd()\n","print(path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"eayyD6x0HV6N","colab":{}},"source":["# change the current working directory to soc591\n","os.chdir(new_path)\n","# check the current wd\n","print(\"Current wd: \",os.getcwd())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"gPIsFA_dIQUB","colab":{}},"source":["# create a new folder for our course\n","new_path=\"./soc591/\"\n","os.makedirs(new_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"U0BFEA1qJlJo","colab":{}},"source":["# let us create a new file in current WD, write some texts into the file, and then close it\n","f = open(\"soc591.txt\",mode=\"w+\")\n","col_vars = \"id;text\\n\"\n","f.write(col_vars)\n","f.write(\"1;This is a demo for writing some texts\\n\")\n","f.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UfZFIIkFMjSR","colab":{}},"source":["# Let us read the soc591.txt file and assign it to variable text_df\n","text_df = open(\"soc591.txt\", \"r\").read()\n","print(text_df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uioZq1WzHhqH","colab":{}},"source":["# list file content\n","os.listdir(\".\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"T0qPwWX7KIZI","colab":{}},"source":["# Let us remove the soc591.txt file\n","os.remove(\"soc591.txt\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"b4pbBNJxD9cY"},"source":["## 2. Play with Regular Expression\n","In this module, we learn about the basic skills to understand, recognize, and write your own python regular expression codes.\n","\n","1. What is regular expression?\n","2. Why should we learn RegEx?\n","3. How to write your own RegEx?\n","If you're interested in text analysis or broad NLP, RegEX would be one element of your necessary toolkit. \n","\n","### What is REGULAR EXPRESSION?\n","Regular expressions, or RegEXes, are an abstract way to express patterns that match strings. It is widely used in natural language processing, for instance, to find and replace certain strings with certain patterns.\n","\n","One simple example is, if you are a data scientist, to create a variable that contains all email address from a large amount of texual data. You can use certain email name pattern to capture all potential email addresses.\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TjaLADkcPXyZ","colab":{}},"source":["import re\n","# re module has a lot of useful function allowing users to search, match, locate,\n","# and replace certain pattern in a string.\n","\n","# Here is an email example\n","email_text = \"Josh Zhang's email is example@email.com\"\n","# RegEx for email address\n","email_regex = \"[a-z]{7}@.*$\"\n","# extract the address\n","email_search = re.search(email_regex,email_text)\n","if email_search:\n","  print(\"Email gets a match: \",email_search)\n","else:\n","  print(\"OOPS...SOMETHING IS WRONG\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-7S8ZrE4SqH4"},"source":["Here, we used re.search() function to search pattern within the email_text. The method returns a match object if the search is successful. You can access the matched text like email_search[0]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d0mPVT8nP8Nc"},"source":["### Why should we use or learn RegEX?\n","If you a data scientist or quantitative scholar, most of your time is to construct some databases based on a large amount of raw data. Obviously, it is not plausible to do manual coding. Even if you could, it would be very expensive and time costly in the big data era. To improve our efficiency, it is better for us to become a master of RegEX.\n","\n","There are couple of ways to generate RegEX automatically using third party algorithms. For instance, you can use RegEx tester tools such as regex101<https://regex101.com/>. \n","\n","But before doing that, you have to be able to understand the meaning of the RegEX pattern.\n","\n","### How to write your own RegEX?\n","There are certain basic RegEXes we need to familier with, including anchors, quantifiers, operators, character classes,boundaries,flags, groupings,back-referencing, look forward and backward,etc.We will go through these topics one by one."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CNZSv0YabLC0"},"source":["#### Let us first see some Sepcial Characters\n","Regular expressions can contain both special and ordinary characters. \n","\n","Most ordinary characters, like 'A', 'a', or '0', are the simplest regular expressions; they simply match themselves. \n","\n","Special characters are characters that are interpreted in a special way by a RegEx engine. \n","\n","The special characters are:\n","\n","**[] . ^ $ * + ? {} () \\ |**\n","\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"APVT9wRrfMoj"},"source":["##### [ ] - Square brackets\n","\n","Square brackets specifies a set of characters you want to match.\n","\n","For instance, [ABCabc] matches if the string contains any of the A, B, C, a, b, or c.\n","\n","You can also specify a range of characters using - inside square brackets.\n","\n","> [A-Ca-c] is the same as [ABCabc].\n","\n","> [1-9] is the same as [123456789].\n","\n","> [0-38] is the same as [01238].\n","\n","You can use caret ^ symbol at the start of a square-bracket to exclude certain characters (equate to saying \"NOT SOME CHARS\").\n","\n","> [^ABCabc] : any character except A OR B OR C OR a OR b OR c.\n","\n","> [^0-9] : any non-digit character."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"NLsSSImffrqW"},"source":["##### .- Dot\n","\n","The dot symbol . matches any single character (except newline '\\n').\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"d3hZ10jAfsTy"},"source":["##### ^ - Caret\n","\n","The caret symbol ^ checks if a string starts with a certain character."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"B9fN0Pjufw1t"},"source":["##### $ - Dollar\n","\n","The dollar symbol $ is used to check if a string ends with a certain character."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4bRZpWYsf4Zt"},"source":["##### \\* - Star\n","\n","The star symbol * matches zero or more occurrences of the pattern left to it."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fgv7b75Uf_MN"},"source":["##### \\+ - Plus\n","\n","The plus symbol + matches one or more occurrences of the pattern left to it."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hhoAHwU1gB2N"},"source":["##### ? - Question Mark\n","\n","The question mark symbol ? matches zero or one occurrence of the pattern left to it"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mE1lmaYzgI02"},"source":["##### {} - Braces\n","\n","Consider this code: {n,m}. This means at least n, and at most m repetitions of the pattern left to it."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aliKphavgQ8X"},"source":["##### | - Alternation\n","\n","Vertical bar | is used for alternation (or operator)."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"859mktKmgVaA"},"source":["##### () - Group\n","\n","Parentheses () is used to group sub-patterns. For example, (a|b|c)xz match any string that matches either a or b or c followed by xz"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"vczrRO-7gW4b"},"source":["##### \\ - Backslash\n","\n","Backlash \\ is used to escape various characters including all metacharacters. For example,\n","\n","\\$a match if a string contains \\$ followed by a. Here, \\$ is not interpreted by a RegEx engine in a special way.\n","\n","If you are unsure if a character has special meaning or not, you can put \\ in front of it. This makes sure the character is not treated in a special way."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"VXdDXHp7glyk"},"source":["### let check some special sequence\n","Special sequences make commonly used patterns easier to write. Here's a list of special sequences:\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"-tEtV_ncguLo"},"source":["\\A - Matches if the specified characters are at the start of a string."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"eVJgma-ngxXO"},"source":["\\b - Matches if the specified characters are at the beginning or end of a word."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"dFMgMMyBg0V7"},"source":["\\B - Opposite of \\b. Matches if the specified characters are not at the beginning or end of a word."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"AFEahvK6g4Aw"},"source":["\\d - Matches any decimal digit. Equivalent to [0-9]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g2IczULGg8KI"},"source":["\\D - Matches any non-decimal digit. Equivalent to [^0-9]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"G4gbpqr1hA8S"},"source":["\\s - Matches where a string contains any whitespace character. Equivalent to [ \\t\\n\\r\\f\\v]."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hM2jDbRuhG_1"},"source":["\\S - Matches where a string contains any non-whitespace character. Equivalent to [^ \\t\\n\\r\\f\\v]."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CioZYeqBhIDk"},"source":["\\w - Matches any alphanumeric character (digits and alphabets). Equivalent to [a-zA-Z0-9_]. By the way, underscore _ is also considered an alphanumeric character.\n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"6VhOrHmwhOux"},"source":["\\W - Matches any non-alphanumeric character. Equivalent to [^a-zA-Z0-9_]"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"OBhTTQ6-hSQJ"},"source":["\\Z - Matches if the specified characters are at the end of a string."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"k9LMKJ599siV"},"source":["#### **Anchors: ^, $, \\b, \\B**\n","\n","> All the patterns youe’ve seen so far will find a match anywhere within a string, which is usually - but not always - what you want. This is the purpose of an anchor; to make sure that you are at a certain boundary before you continue the match. \n","\n","> The caret symbol ^ matches the beginning of a line, and the dollar sign \\$ matches the end of a line. \n","\n","> The other two anchors are \\b and \\B, which stand for a “word boundary” and “non-word boundary”. Here is an exmaple:\n","\n","> > \"\\bame\" will capture \"i am american\", but not \"i am an blamer\".\n","\n","> > \"\\bnational\" will capture \"national flag is abcde\" but not \"internatonal organizations are abbbb\"."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Ri9yplfGcfxg"},"source":["#### **Quantifiers: {}, +, *, ?\n","\n","> These symbols are quantifiers used in regEX to indicate the repetition or the frequency of certain characters \n","\n","> > {a,b} a times at least, b times at most\n","\n","> > \\+ at least once\n","\n","> > \\* zero times or more\n","\n","> > ? zero times or once"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SAUrW4oIecnr"},"source":["#### **Greedy Match or Lazy Match**\n","\n","We use * or ? to do greedy (longest search) or lazy match (shortest search).\n","\n","> > For instance, pattern \"i.*nat\" will capture i am a national representative in an internat\" in the string \"i am a national representative in an international organization\".\n","\n",">> But \"i.*?nat\" will only capture \"i am a nat\"."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"WXOQoInLbAjG"},"source":["**Let us do a quick test**\n","\n","r\"(\\d|[a-c]){2}.\\*? \\bame.\\*$\""]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"gWP_n7DdinUY"},"source":["### Let us check python re module's fuctions that we often use\n","\n","If you want to learn more python regEX, you can visit this link: <https://docs.python.org/3/library/re.html>. \n","\n","Here we only cover several widely used ones:\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QZUxKwP8is22"},"source":["**re.findall(pattern, string, flags=0)**\n","\n","> This methods returns all non-overlapping matches of pattern in string, as a list of strings. \n","\n","> The string is scanned left-to-right, and matches are returned in the order found. So we often use this function to retrieve data."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"sgKJL7smKMdU","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"elapsed":359,"status":"ok","timestamp":1598839986135,"user":{"displayName":"Yongjun Zhang","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gimk07UnSWf8tgoIgpz-30olfpE49PRXAOwGrYb1RI=s64","userId":"16913951745033588592"},"user_tz":240},"outputId":"cf0d9bd7-035b-4460-a756-f990f4d450ad"},"source":["import re \n","# A sample text string where regular expression is searched. \n","string = \"\"\"STONY BROOK UNIVERSITY ZIPCODE IS 11794, \n","            MY ID IS 12398774, YOU ID IS 8966AGVGG\"\"\"\n","# A sample regular expression to find digits. \n","pattern = '\\d+'\t\t\t\n","match = re.findall(pattern, string) \n","print(match) "],"execution_count":null,"outputs":[{"output_type":"stream","text":["['11794', '12398774', '8966']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Amp0fVcviwvi"},"source":["**re.match(pattern, string, flags=0)**\n","\n","> If zero or more characters at the beginning of string match the regular expression pattern, return a corresponding match object. \n","\n","> Return None if the string does not match the pattern; note that this is different from a zero-length match.\n","\n","> Note that even in MULTILINE mode, re.match() will only match at the beginning of the string and not at the beginning of each line."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"0bdZiIvo7SEL","colab":{}},"source":["import re\n","\n","pattern =  r\"^\\d+\"\n","string = \"\"\"11794 is a valid stony brook address.\\n \n","            this is another test\\n \n","            889997 is my phone number.\"\"\"\n","result = re.match(pattern,string,re.M)\n","print(result)\n","print(result.group(0))\n","\n","# Note that even in MULTILINE mode, \n","# re.match() will only match at the beginning of the string \n","# and not at the beginning of each line.\n","result_m = re.match(pattern,string,re.M)\n","print(result_m)\n","print(result_m.group(0))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iV70MOIKi0nY"},"source":["**re.search(pattern, string, flags=0)**\n","\n","> Scan through string looking for the first location where the regular expression pattern produces a match, and return a corresponding match object. \n","\n","> Return None if no position in the string matches the pattern; note that this is different from finding a zero-length match at some point in the string."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"uhkQaMl7PFJW","colab":{}},"source":["import re\n","\n","pattern = r\"^\\d+\"\n","string = \"\"\"11794 is a valid stony brook address.\\n \n","            this is another test\\n \n","            889997 is my phone number.\"\"\"\n","result=re.search(pattern,string)\n","print(result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"_o_ebN78i4YU"},"source":["**re.sub(pattern, repl, string, count=0, flags=0)**\n","\n","> Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl. If the pattern isn’t found, string is returned unchanged. \n","\n","> repl can be a string or a function; if it is a string, any backslash escapes in it are processed. That is, \\n is converted to a single newline character, \\r is converted to a carriage return, and so forth. Unknown escapes of ASCII letters are reserved for future use and treated as errors. Other unknown escapes such as \\& are left alone. Backreferences, such as \\6, are replaced with the substring matched by group 6 in the pattern. "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"teXimKy2VlpE","colab":{}},"source":["import re\n","# replace all digits to DIGITS\n","pattern = r\"\\d+\"\n","repl = \"DIGITS\"\n","string = \"\"\"11794 is a valid stony brook address.\\n \n","            this is another test\\n \n","            889997 is my phone number.\"\"\"\n","result = re.sub(pattern,repl,string)\n","print(result)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hparCXI1jDjN"},"source":["**re.split(pattern, string, maxsplit=0, flags=0)**\n","\n","> Split string by the occurrences of pattern. \n","\n","> If capturing parentheses are used in pattern, then the text of all groups in the pattern are also returned as part of the resulting list. \n","\n","> If maxsplit is nonzero, at most maxsplit splits occur, and the remainder of the string is returned as the final element of the list."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"y5lPt4xuNm4b","colab":{}},"source":["print(re.split(r'\\W+', 'Words, words, words.'))\n","\n","print(re.split(r'(\\W+)', 'Words, words, words.'))\n","\n","print(re.split(r'\\W+', 'Words, words, words.', 1))\n","\n","print(re.split('[a-f]+', '0a3B9', flags=re.IGNORECASE))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oyPBZfdEYy5K"},"source":["#### regEX is especially useful when you are using lexicon methods to create variables from large texual data. Let us go through some examples\n","\n","> I was working on a project focusing on social movement organizations testifying before U.S. Congress. We need to detect whether certain SMO appears in some hearings. For instance, we need to make whether afl-cio was mentioned in some hearings. So we could specify a regEX to capture afl-cio."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DTPYTOvLrdbe"},"source":["## Part 2: Using Webscraping to Collect Text Data"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"XfCeH0CifVtS"},"source":["### 1. Basic info on webpages\n","\n","Web-scraping is automating the ways how we gather data from websites. It is more efficient, but imposing burdens on servers. That is why a lot of websites develop anti-robot measures to prevent automate data gathering. You should always check robots.txt from the target website to see whether it allows you to scrape. \n","\n","For most of the time, we can scrape those government websites because they disclose massive data for the public such as FEC and SEC websites. \n","\n","Some of these websites are straightfoward. They are static. You can go their webpage and scrape all their stuff easily.\n","\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Drq6KQqJg0jH","colab":{}},"source":["# Here is an example of static html page\n","<!DOCTYPE html>\n","<html>\n","<head>\n","<title>Page Title</title>\n","</head>\n","<body>\n","\n","<h1>This is a Heading</h1>\n","<p>This is a paragraph.</p>\n","\n","</body>\n","</html>"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"mc-aT1tLhVdc"},"source":["But sometimes we have dynamic and interactive websites built on JavaScript, PHP, etc. For instance, a lot of data visualizaton websites, you have to click on something, then the website will return some results. \n","\n","One solution to this is to use Selenium to simulate browser behavior."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"5TfhVQUpiP2u"},"source":["### 2. Scraping Static Webpages"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"-cd7NHhHii6H","colab":{}},"source":["import pandas as pd\n","from bs4 import BeautifulSoup as bs\n","import urllib.parse\n","import urllib.request\n","\n","def get_crp_industry_list(url):\n","  ''' Access Opensecrets.org website and return industry names and ids.\n","  '''\n","  # Specify userheader\n","  userHeader = {\"User-Agent\":\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_4) AppleWebKit/600.7.12 (KHTML, like Gecko) Version/8.0.7 Safari/600.7.12\"}\n","  req = urllib.request.Request(url, headers=userHeader)\n","  # open url and read web page\n","  response = urllib.request.urlopen(req)\n","  the_page = response.read()\n","  # beautifulsoup parse html\n","  soup=bs(the_page,\"html.parser\")\n","  #print(soup)\n","  # get all industry links and names\n","  indList=soup.find(\"div\",{\"id\":\"rightColumn\"}).find_all(\"a\")\n","  #print(indList)\n","  # clean raw data\n","  indLinks = []\n","  indNames = []\n","  for link in indList[1:]:\n","      indLinks.append(link['href'].replace(\"indus.php?ind=\",\"\"))\n","      indNames.append(link.contents[0].strip())\n","  #print(indLinks,indNames)\n","  # create a dataset\n","  indDF = pd.DataFrame({\"indLinks\":indLinks,\"indNames\":indNames})\n","  return indDF\n","\n","url=\"https://www.opensecrets.org/industries/slist.php\"\n","data_ind_list=get_crp_industry_list(url)\n","print(data_ind_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pU21RSm1f-i7"},"source":["### 3. Using Selenium to Scrape Dynamic and Interactive Websites\n","\n","So what is selenium? Selenium is an open-source web-based automation tool used for testing in the industry. But it can also used for wescraping, or \"crawling/spiderig\". \n","\n","Selenium can control your web browser and automate your browsing behavior. We will use Google chrome driver, but you can also other drivers like firefox,IE,etc."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"MhSjVw3Kqq1G"},"source":["#### First we need to install necessary modules for webscraping via terminal or commind line"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vHkVlKxZYw2k","colab":{}},"source":["#!pip install selenium\n","!pip install webdriver_manager\n","!pip install bs4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"4LWhDSQsZJzo"},"source":["#### The Goal here is to scrape Black Lives Matter Data from https://elephrame.com/\n","\n","This website tracks the occurence of BLM protests. We cannot use the previous way to directly get the data because it is dynamic and you have to scroll down or click next page to get more data.\n","\n","Let us build our cralwer from scratches...\n","\n","1. We need to install webdriver to control our browser\n","2. We need to use our webdriver to control brower to establish a connection with the target website (sometimes you have to do someth log-in stuff, send pwd, etc.)\n","3. We need to check the target webpage to locate the info we need\n","4. Scrape the target info, open a file on local computer or your server, and save that info.\n","5. We click the next page and repeat the scraping process until the end\n","5. Close your webdriver\n","6. We encapsulate the whole process (def a function or class to automate the whole process)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"HftAgnL9ZIzF","colab":{}},"source":["# Import modules for use\n","import os\n","import selenium\n","from selenium import webdriver\n","import time\n","import requests\n","from webdriver_manager.chrome import ChromeDriverManager\n","from selenium.common.exceptions import ElementClickInterceptedException\n","from bs4 import BeautifulSoup as bs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"YRRicwm-Zj_Q","colab":{}},"source":["# Install Driver\n","driver = webdriver.Chrome(ChromeDriverManager().install())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1sPkidNDLrwn","colab_type":"code","colab":{}},"source":["# Open the url and establish a connection\n","url = \"https://elephrame.com/textbook/BLM/chart\"\n","driver.implicitly_wait(5)\n","driver.maximize_window()\n","driver.get(url)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XztdUQ76Lrwq","colab_type":"code","colab":{}},"source":["# Scroll down to the bottom of the page\n","#driver.execute_script(\"window.scrollTo(0,window.scrollY+300)\")\n","driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NutwGvYCsOk5","colab":{}},"source":["# Read and parse the first page\n","first_page = driver.page_source\n","soup = bs(first_page,\"html.parser\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xCniDLLZXM-t","colab":{}},"source":["# Use google developer inspect to check the source codes\n","# locate the key info we need\n","# it stores ad div class = \"item chart\"\n","items = soup.findAll(\"div\",{\"class\":\"item chart\"})\n","print(items)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZgMEmmynlrZt","scrolled":true,"colab":{}},"source":["# find necessay elements, including id, item-protest-location,protest-start,protest-end,item-protest-subject\n","# item-protest-participants (li), item-protest-time,item-protest-description, item-protest-url\n","import re\n","for item in items:\n","    try:\n","        id=re.findall(r'id=\"([0-9].*?)\"',str(item))[0]\n","        print(id)\n","    except:\n","        id=NA\n","    try:\n","        protest_location=' '.join(item.find(\"div\",{\"class\":\"item-protest-location\"}).text.split())\n","        print(protest_location)\n","    except:\n","        protest_location=\"\"\n","    try:\n","        protest_start=' '.join(item.find(\"div\",{\"class\":\"protest-start\"}).text.split())\n","        print(protest_start)\n","    except:\n","        protest_start=\"\"\n","    try:\n","        protest_end=' '.join(item.find(\"div\",{\"class\":\"protest-end\"}).text.split())\n","        print(protest_end)\n","    except:\n","        protest_end=\"\"\n","    try:\n","        protest_subject=' '.join(item.find(\"li\",{\"class\":\"item-protest-subject\"}).text.split())\n","        print(protest_subject)\n","    except:\n","        protest_subject=\"\"\n","    try:\n","        protest_participants=' '.join(item.find(\"li\",{\"class\":\"item-protest-participants\"}).text.split())\n","        print(protest_participants)\n","    except:\n","        protest_participants=\"\"\n","    try:\n","        protest_time=' '.join(item.find(\"li\",{\"class\":\"item-protest-time\"}).text.split())\n","        print(protest_time)\n","    except:\n","        protest_time=\"\"\n","    try:\n","        protest_description=' '.join(item.find(\"li\",{\"class\":\"item-protest-description\"}).text.split())\n","        print(protest_description)\n","    except:\n","        protest_description=\"\"\n","    try:\n","        protest_urls='##'.join(item.find(\"li\",{\"class\":\"item-protest-url\"}).text.split())\n","        print(protest_urls,\"\\n\")\n","    except:\n","        protest_urls=\"\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"10Eahk79ls7t","colab":{}},"source":["# save the last item content into a tsv file for check\n","# check current dir\n","os.getcwd()\n","#os.chdir()\n","import csv \n","with open('blm-data.tsv','w+') as f:\n","    tsv_writer = csv.writer(f, delimiter='\\t')\n","    # write column names\n","    var_names=[\"protest_id\", \"protest_location\",\"protest_start\",\"protest_end\",\"protest_subject\",\"protest_participants\", \n","            \"protest_time\",\"protest_description\", \"protest_urls\"]\n","    tsv_writer.writerow(var_names)\n","    # write actual data\n","    data=[protest_id, protest_location,protest_start,protest_end,protest_subject,protest_participants, \n","            protest_time,protest_description, protest_urls]\n","    tsv_writer.writerow(data)\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f-ToSyBELrw3","colab_type":"code","colab":{}},"source":["# Open tsv file for manual check\n","!open blm-data.tsv"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"UJGJtCz2lxzH","colab":{}},"source":["# click the next page\n","# you can check here for more info on selenium how to locate elements \n","# https://selenium-python.readthedocs.io/locating-elements.html\n","import time\n","from selenium.webdriver.common.by import By\n","next_page = driver.find_element(By.XPATH, '//*[@id=\"blm-results\"]/div[3]/ul/li[4]')\n","next_page.click()\n","time.sleep(5)\n","# then we repeat the process to the end"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vKMSudJ1LrxL","colab_type":"code","colab":{}},"source":["# Because we have 229 pages, so we need a loop to automate the process\n","soup = bs(driver.page_source,\"html.parser\")\n","# locate the page id\n","page_id = soup.find(\"input\",{\"class\":\"page-choice\"})[\"value\"]\n","page_id = int(page_id)\n","print(page_id)\n","'''\n","while page_id <=229:\n","    # do first page scraping \n","    # click next page\n","    # repeat the scraping\n","    # if page_id>229, then stop\n","'''"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PKub3SahMelN","colab_type":"text"},"source":["#### So we need to put the whole process into a couple of functions and automate the whole scraping process."]},{"cell_type":"code","metadata":{"id":"p2tUmlc_LrxO","colab_type":"code","colab":{}},"source":["# let us encapsulate the whole process\n","import os,re,csv\n","import selenium\n","from selenium import webdriver\n","import time\n","import requests\n","from webdriver_manager.chrome import ChromeDriverManager\n","from selenium.common.exceptions import ElementClickInterceptedException\n","from bs4 import BeautifulSoup as bs\n","from selenium.webdriver.common.by import By\n","\n","# Let us define a couple of functions for ease of writing the loop\n","# first let us define a function to set up the driver\n","def driver_setup(url):\n","    # install the driver and initiate it\n","    driver = webdriver.Chrome(ChromeDriverManager().install())\n","    # url = \"https://elephrame.com/textbook/BLM/chart\"\n","    #driver.implicitly_wait(10)\n","    #driver.maximize_window()\n","    driver.get(url)\n","    time.sleep(20)\n","    return driver\n","\n","# second let us define a function to scrape each page\n","def scrape_page(driver):\n","    '''Access driver page source, and scrape all the necessary info,\n","    return a list of vars named data'''\n","    # we get the first page, voila, initiate page_id=1\n","    page_id=1\n","    # Let us open a tsv file for saving our data\n","    with open('blm-data.tsv','w+') as f:\n","        tsv_writer = csv.writer(f, delimiter='\\t')\n","        # write column names\n","        var_names=[\"page_id\",\"protest_id\", \"protest_location\",\"protest_start\",\"protest_end\",\"protest_subject\",\"protest_participants\", \n","                \"protest_time\",\"protest_description\", \"protest_urls\"]\n","        tsv_writer.writerow(var_names)\n","        # loop the website to get all pages\n","        while page_id<=229:\n","            try:\n","                driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n","                page = driver.page_source\n","                soup = bs(page,\"html.parser\")\n","                items = soup.findAll(\"div\",{\"class\":\"item chart\"})\n","                # iterating all items\n","                for item in items:\n","                    try:\n","                        protest_id=re.findall(r'id=\"([0-9].*?)\"',str(item))[0]\n","                        print(protest_id)\n","                    except:\n","                        protest_id=\"\"\n","                    try:\n","                        protest_location=' '.join(item.find(\"div\",{\"class\":\"item-protest-location\"}).text.split())\n","                        print(protest_location)\n","                    except:\n","                        protest_location=\"\"\n","                    try:\n","                        protest_start=' '.join(item.find(\"div\",{\"class\":\"protest-start\"}).text.split())\n","                        print(protest_start)\n","                    except:\n","                        protest_start=\"\"\n","                    try:\n","                        protest_end=' '.join(item.find(\"div\",{\"class\":\"protest-end\"}).text.split())\n","                        print(protest_end)\n","                    except:\n","                        protest_end=\"\"\n","                    try:\n","                        protest_subject=' '.join(item.find(\"li\",{\"class\":\"item-protest-subject\"}).text.split())\n","                        print(protest_subject)\n","                    except:\n","                        protest_subject=\"\"\n","                    try:\n","                        protest_participants=' '.join(item.find(\"li\",{\"class\":\"item-protest-participants\"}).text.split())\n","                        print(protest_participants)\n","                    except:\n","                        protest_participants=\"\"\n","                    try:\n","                        protest_time=' '.join(item.find(\"li\",{\"class\":\"item-protest-time\"}).text.split())\n","                        print(protest_time)\n","                    except:\n","                        protest_time=\"\"\n","                    try:\n","                        protest_description=' '.join(item.find(\"li\",{\"class\":\"item-protest-description\"}).text.split())\n","                        print(protest_description)\n","                    except:\n","                        protest_description=\"\"\n","                    try:\n","                        protest_urls='##'.join(item.find(\"li\",{\"class\":\"item-protest-url\"}).text.split())\n","                        print(protest_urls,\"\\n\")\n","                    except:\n","                        protest_urls=\"\"\n","                    data=[page_id,protest_id, protest_location,protest_start,protest_end,protest_subject,protest_participants, \n","                        protest_time,protest_description, protest_urls]\n","                    tsv_writer.writerow(data)\n","            except:\n","                print(\"SOMETHING IS WRONG...\\n\")\n","                break\n","            # click next page\n","            try:\n","                if page_id==229:\n","                  break\n","                else:\n","                  pass\n","                driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n","                driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n","                time.sleep(3)\n","                next_page = driver.find_element(By.XPATH, '//*[@id=\"blm-results\"]/div[3]/ul/li[4]')\n","                next_page.click()\n","                time.sleep(3)\n","                # update page_id\n","                page = driver.page_source\n","                soup = bs(page,\"html.parser\")\n","                page_id = soup.find(\"input\",{\"class\":\"page-choice\"})[\"value\"]\n","                page_id = int(page_id)\n","                print(page_id)\n","            except:\n","                print(\"CLICKING NEXT PAGE FAILS...\\n\")\n","                break\n","\n","def main():\n","    # set up the driver\n","    url = \"https://elephrame.com/textbook/BLM/chart\"\n","    driver = driver_setup(url)\n","    scrape_page(driver)\n","    \n","main()\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4dAS8iyrMvB4","colab_type":"text"},"source":["#### Sometimes your webdriver keeps refreshing is annoying. You can use headless to not show your browser running"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1Xcsq6NcdSS0","colab":{}},"source":["chrome_options = webdriver.ChromeOptions()\n","#chrome_options.add_argument('--headless')\n","#chrome_options.add_argument('--no-sandbox')\n","#chrome_options.add_argument('--disable-dev-shm-usage')\n","driver =webdriver.Chrome('chromedriver',chrome_options=chrome_options)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4QoQ_y9rL8Up","colab_type":"text"},"source":["## We don't have enough time to learn NLTK in python. Please read the NLP with Python Book first three chapters for more tech details."]}]}