---
title: "Attention-Based LSTM for Psychological Stress Detection from Spoken Language Using Distant Supervision"
collection: publications
permalink: /publication/2018-05-31-attention-based-lstm
excerpt: 'We propose a Long Short-Term Memory (LSTM) with attention mechanism to classify 
psychological stress from self-conducted interview transcriptions. We apply distant 
supervision by automatically labeling tweets based on their hashtag content, which 
complements and expands the size of our corpus. This additional data is used to initialize 
the model parameters, and which it is fine-tuned using the interview data. This improves the 
model's robustness, especially by expanding the vocabulary size. The bidirectional LSTM 
model with attention is found to be the best model in terms of accuracy (74.1%) and f-score 
(74.3%). Furthermore, we show that distant supervision fine-tuning enhances the model's 
performance by 1.6% accuracy and 2.1% f-score. The attention mechanism helps the model 
to select informative words.'
date: 2018-05-31
venue: 'arXiv preprint'
paperurl: 'https://arxiv.org/pdf/1805.12307.pdf'
citation: 'Genta Indra Winata, Onno Kampman, Pascale Fung. (2018). &quot;Attention-Based LSTM for Psychological Stress Detection from Spoken Language Using Distant Supervision.&quot; <i>arXiv preprint</i>. 1(3).'
---
We propose a Long Short-Term Memory (LSTM) with attention mechanism to classify 
psychological stress from self-conducted interview transcriptions. We apply distant 
supervision by automatically labeling tweets based on their hashtag content, which 
complements and expands the size of our corpus. This additional data is used to initialize 
the model parameters, and which it is fine-tuned using the interview data. This improves the 
model's robustness, especially by expanding the vocabulary size. The bidirectional LSTM 
model with attention is found to be the best model in terms of accuracy (74.1%) and f-score 
(74.3%). Furthermore, we show that distant supervision fine-tuning enhances the model's 
performance by 1.6% accuracy and 2.1% f-score. The attention mechanism helps the model 
to select informative words.

[Download paper here](https://arxiv.org/pdf/1805.12307.pdf)

Recommended citation: Winata et al. (2018). "Attention-Based LSTM for Psychological Stress Detection from Spoken Language Using Distant Supervision." <i>arXiv preprint</i>. 1(3).