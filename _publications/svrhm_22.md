---
title: "Exploring the role of image domains in self-supervised DNN models of rodent brains"
collection: publications
permalink: /publication/prasad_et_al_22_svrhm
abstract: 'Biological visual systems have evolved around the efficient coding of natural image statistics in order to support recognition of complex visual patterns. Recent work has shown that deep neural networks are able to learn similar representations to those measured in visual areas in animals, suggesting they may serve as models for the brain. Varying network architectures and loss functions has been shown to modulate the biological similarity learned representations, however the extent to which this results from exposure to natural image statistics during training has not been fully characterized. Here, we use self-supervised learning to train neural network models across a range of data domains with different image statistics and evaluate the similarity of the learned representations to neural activity of the mouse visual cortex. We find that networks trained on different domains also exhibit different responses when shown held-out natural images. Furthermore, we find that the degree of biological similarity of the representations generally increases as a function of the naturalness of the data domain used for training. Our results provide evidence for the idea that that the training data domain is an important component when modeling the visual system using deep neural networks.'
date: 2022-10-17
venue: 'The Fourth Shared Visual Representions in Humans and Machines (SVRHM) Workshop at the Thirty-sixth Conference on Neural Information Processing Systems (NeurIPS)'
paperurl: 'https://openreview.net/forum?id=KIlSyKTulXO'
citation: 'Prasad, et al. (2022). &quot;Exploring the role of image domains in self-supervised DNN models of rodent brains.&quot; <i>The 4^{th} Shared Visual Representions in Humans and Machines Workshop at the Thirty-sixth Conference on Neural Information Processing Systems </i>.'
---
Abstract: Biological visual systems have evolved around the efficient coding of natural image statistics in order to support recognition of complex visual patterns. Recent work has shown that deep neural networks are able to learn similar representations to those measured in visual areas in animals, suggesting they may serve as models for the brain. Varying network architectures and loss functions has been shown to modulate the biological similarity learned representations, however the extent to which this results from exposure to natural image statistics during training has not been fully characterized. Here, we use self-supervised learning to train neural network models across a range of data domains with different image statistics and evaluate the similarity of the learned representations to neural activity of the mouse visual cortex. We find that networks trained on different domains also exhibit different responses when shown held-out natural images. Furthermore, we find that the degree of biological similarity of the representations generally increases as a function of the naturalness of the data domain used for training. Our results provide evidence for the idea that that the training data domain is an important component when modeling the visual system using deep neural networks.

[Read the paper here!](https://openreview.net/forum?id=KIlSyKTulXO)

Recommended citation: Prasad, et al. (2022). "Exploring the role of image domains in self-supervised DNN models of rodent brains." <i>The 4^{th} Shared Visual Representions in Humans and Machines Workshop at the Thirty-sixth Conference on Neural Information Processing Systems</i>.
