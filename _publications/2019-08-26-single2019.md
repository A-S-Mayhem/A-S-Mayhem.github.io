---
title: "Single vision-based self-localization for autonomous robotic agents"
collection: publications
permalink: /publication/2019-08-26-single2019
excerpt: 'We present a single vision-based, self-localization method for autonomous mobile robots in a known, indoor environment. This absolute localization method is landmark assisted, therefore, we propose an algorithm that requires the extraction of a single landmark feature i.e., the length of a known edge. Our technique is based on measuring the distance from two distinct, arbitrarily positioned landmarks in the robot&apos;s environment, the locations of which are known a priori. A single camera vision system is used to perform distance estimation. The developed framework is applied to tracking a robot&apos;s pose, i.e., its position and orientation, in a Cartesian coordinate system. The position of the robot is estimated using a bilateration method, while its orientation calculation utilizes tools from projective geometry. The validity and feasibility of the approach are demonstrated through experiments.'
date: 2019-08-26
venue: '2019 7th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW)'
paperurl: 'https://pureadmin.qub.ac.uk/ws/files/175176852/AIRS2_19_paper_6_1_.pdf'
citation: 'Avgeris, M., Spatharakis, D., Athanasopoulos, N., Dechouniotis, D., &amp; Papavassiliou, S. (2019, August). &quot;Single vision-based self-localization for autonomous robotic agents.&quot; <i>2019 7th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW)</i>. (pp. 123-129). IEEE.'
---
We present a single vision-based, self-localization method for autonomous mobile robots in a known, indoor environment. This absolute localization method is landmark assisted, therefore, we propose an algorithm that requires the extraction of a single landmark feature i.e., the length of a known edge. Our technique is based on measuring the distance from two distinct, arbitrarily positioned landmarks in the robot&apos;s environment, the locations of which are known a priori. A single camera vision system is used to perform distance estimation. The developed framework is applied to tracking a robot&apos;s pose, i.e., its position and orientation, in a Cartesian coordinate system. The position of the robot is estimated using a bilateration method, while its orientation calculation utilizes tools from projective geometry. The validity and feasibility of the approach are demonstrated through experiments.

[Download paper here](https://pureadmin.qub.ac.uk/ws/files/175176852/AIRS2_19_paper_6_1_.pdf)

Recommended citation: Avgeris, M., Spatharakis, D., Athanasopoulos, N., Dechouniotis, D., & Papavassiliou, S. (2019, August). "Single vision-based self-localization for autonomous robotic agents." <i>2019 7th International Conference on Future Internet of Things and Cloud Workshops (FiCloudW)</i>. (pp. 123-129). IEEE.