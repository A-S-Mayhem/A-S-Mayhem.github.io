---
title: "Multi-objective reinforcement learning for power allocation in massive MIMO networks: A Solution to spectral and energy trade-offs"
collection: publications
permalink: /publication/2023-ij2
date: 2023-12-28
venue: 'IEEE Access'
# paperurl: ''
pubtype: 'international_journal'
# just display our icon symbols
link: 'https://ieeexplore.ieee.org/document/10375483'
# code: ' '
github: 'https://github.com/FIVEYOUNGWOO/Mutli-Objective-Reinforcement-Learning-2-Proposed-Federated-MO-A3Cs'
citation: 'Youngwoo Oh, Arif Ullah and Wooyeol Choi. &quot;Multi-objective reinforcement learning for power allocation in massive MIMO networks: A solution to spectral and energy trade-offs.&quot; <i>IEEE Access</i>, vol. 12, pp.1172-1188, Dec. 2023. (IF: 3.9 / JCR 2022)'

excerpt_separator: ""
abstract: "The joint optimization of spectral and energy efficiency through power allocation techniques is a critical requirement for emerging fifth-generation and beyond networks. While various algorithmic approaches, such as genetic algorithms and convex optimization, have been considered for optimizing the trade-offs between spectral and energy efficiency in cellular networks, these methods suffer from high computational costs. Deep reinforcement learning-based methods have shown promise in addressing the computational challenges of single-objective optimization problems in wireless networks. Despite the potential of deep reinforcement learning approaches, utilizing them for the joint optimization of spectral and energy efficiency has yet to be noticed in the existing literature. In this paper, we propose a downlink transmit power allocation method based on a multi-objective asynchronous advantage single actorâ€“multiple critics model. This method aims to optimize spectral and energy efficiency trade-offs in massive multiple-input-multiple-output assisted multi-cell networks. Furthermore, we also propose a Bayesian rule-based preference weight updating mechanism, multi-objective advantage function, and balanced-reward aggregation method. These proposed methods ensure effective training and control biases toward any specific objective reward during the training process of our model.  Based on extensive simulations, we demonstrate that the proposed model-based power allocation method outperforms the other techniques, especially Pareto front approximation policy-driven multi-objective reinforcement learning-based power allocation strategies."
---