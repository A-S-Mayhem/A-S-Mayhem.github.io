---
title: "Towards Exploiting Background Knowledge for Building Conversation Systems"
collection: publications
venue: 2018 Conference on Empirical Methods in Natural Language Processing, EMNLP 2018
permalink: /publications/2019-11-holl-e-number-2
paperurl: https://www.aclweb.org/anthology/D18-1255/
---
Authors: Nikita Moghe, Siddhartha Arora, Suman Banerjee and Mitesh M. Khapra

[paper](https://www.aclweb.org/anthology/D18-1255/) [data and code](https://github.com/nikitacs16/Holl-E) [slides](https://docs.google.com/presentation/d/15C8sV26mHTHHauZ-Lx6w2ApFXutCiDjEpU3ZSGUFpGo/edit#slide=id.p) [video](https://vimeo.com/305939688) [leaderboard] (https://nikitacs16.github.io/holl-e-website/)

Existing dialog datasets contain a sequence of utterances and responses without any explicit background knowledge associated with them. This has resulted in the development of models which treat conversation as a sequence-to-sequence generation task (i.e., given a sequence of utterances generate the response sequence). This is not only an overly simplistic view of conversation but it is also emphatically different from the way humans converse by heavily relying on their background knowledge about the topic (as opposed to simply relying on the previous sequence of utterances). For example, it is common for humans to (involuntarily) produce utterances which are copied or suitably modified from background articles they have read about the topic. To facilitate the development of such natural conversation models which mimic the human process of conversing, we create a new dataset containing movie chats wherein each response is explicitly generated by copying and/or modifying sentences from unstructured background knowledge such as plots, comments and reviews about the movie. We establish baseline results on this dataset (90K utterances from 9K conversations) using three different models: (i) pure generation based models which ignore the background knowledge (ii) generation based models which learn to copy information from the background knowledge when required and (iii) span prediction based models which predict the appropriate response span in the background knowledge.
