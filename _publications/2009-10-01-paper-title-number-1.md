---
title: "When Causal Intervention Meets Adversarial Examples and Image Masking for Deep Neural Networks"
collection: publications
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'This paper is about the number 1. The number 2 is left for future work.'
date: 2019-09-30
venue: 'Journal 1'
paperurl: 'https://arxiv.org/pdf/1902.03380.pdf'
citation: 'Yang, C. H. H., Liu, Y. C., Chen, P. Y., Ma, X., & Tsai, Y. C. J. (2019). When Causal Intervention Meets Image Masking and Adversarial Perturbation for Deep Neural Networks. arXiv preprint arXiv:1902.03380.; <i>International Conference of Image Processing </i>. .'
---

Our Pytorch implementation has released [here](https://github.com/jjaacckkyy63/Causal-Intervention-AE-wAdvImg). 

Discovering and exploiting the causality in deep neural networks (DNNs) are crucial challenges for understanding and reasoning causal effects (CE) on an explainable visual model. "Intervention" has been widely used for recognizing a causal relation ontologically. In this paper, we propose a causal inference framework for visual reasoning via do-calculus. To study the intervention effects on pixel-level feature(s) for causal reasoning, we introduce pixel-wise masking and adversarial perturbation. In our framework, CE is calculated using features in a latent space and perturbed prediction from a DNN-based model. We further provide a first look into the characteristics of discovered CE of adversarially perturbed images generated by gradient-based methods. Experimental results show that CE is a competitive and robust index for understanding DNNs when compared with conventional methods such as class-activation mappings (CAMs) on the ChestX-ray 14 dataset for human-interpretable feature(s) (e.g., symptom) reasoning. Moreover, CE holds promises for detecting adversarial examples as it possesses distinct characteristics in the presence of adversarial perturbations.


### Paper: WP.L7.4 -- When Causal Intervention Meets Adversarial Examples and Image Masking for Deep Neural Networks

- [Session: WP.L7 -- Special Session - Explainable Machine Learning for Image Processing](https://cmsworkshops.com/ICIP2019/Papers/ViewSession.asp?SessionID=1141)

Session Format: Lecture

Session Time: Wednesday, September 25, 14:00 - 16:00

Session Location: Room 201DE (2F)

[Paper Presentation Time: Wednesday, September 25, 15:00 - 15:20 (20 minutes)](https://cmsworkshops.com/ICIP2019/Papers/ViewPaper.asp?PaperNum=3211)


bib file

``@article{yang2019causal,
  title={When Causal Intervention Meets Adversarial Examples and Image Masking for Deep Neural Networks},
  author={Yang, Chao-Han Huck and Liu, Yi-Chieh and Chen, Pin-Yu and Ma, Xiaoli and Tsai, Yi-Chang James},
  journal={26th IEEE International Conference on Image Processing (ICIP)},
  year={2019}
}``
***
