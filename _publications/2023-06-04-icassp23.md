---
title: "Dynamic Selection of p-Norms in Linear Adaptive Filtering via online
Kernel-based Reinforcement Learning"
collections: publications
category: conferences
permalink: /publication/2023-06-04-icassp23
excerpt: "This study addresses the problem of selecting dynamically the optimal
p-norm to combat outliers in linear adaptive filtering."
date: 2023-06-04
venue: 'IEEE International Conference of Acoustics, Speech and Signal Processing
(ICASSP)'
paperurl: 'https://doi.org/10.1109/ICASSP49357.2023.10096825'
citation: 'M. Vu, Y. Akiyama and K. Slavakis. (2023) &quot;Dynamic Selection of
p-norm in Linear Adaptive Filtering via online Kernel-based Reinforcement
Learning.&quot; <i>ICASSP 2023 - 2023 IEEE International Conference on
Acoustics, Speech and Signal Processing (ICASSP)</i>, Rhodes Island, Greece,
2023, pp. 1-5.
'
---

![ICASSP 23](/images/icassp23.jpg "2023 IEEE ICASSP")

This study addresses the problem of selecting dynamically, at each time
instance, the "optimal" p-norm to combat outliers in linear adaptive filtering
without any knowledge on the potentially time-varying probability density
function of the outliers. To this end, an online and data-driven framework is
designed via kernel-based reinforcement learning (KBRL). Novel Bellman mappings
on reproducing kernel Hilbert spaces (RKHSs) are introduced that need no
knowledge on transition probabilities of Markov decision processes, and are
nonexpansive with respect to the underlying Hilbertian norm. An approximate
policy-iteration framework is finally offered via the introduction of a
finite-dimensional affine superset of the fixed-point set of the proposed
Bellman mappings. The well-known "curse of dimensionality" in RKHSs is addressed
by building a basis of vectors via an approximate linear dependency criterion.
Numerical tests on synthetic data demonstrate that the proposed framework
selects the "optimal" p-norm for the outlier scenario at hand at every time
instance, outperforming several non-RL and KBRL schemes.
