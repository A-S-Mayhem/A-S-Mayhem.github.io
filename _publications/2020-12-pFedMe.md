---
title: "Personalized Federated Learning with Moreau Envelopes"
collection: publications
permalink: /publication/2020-12-pFedMe
date: 2020-12-07
venue: '34th Conference on Neural Information Processing Systems (NeurIPS 2020)'
citation: 'Canh T. Dinh, Nguyen Tran and Tuan Dung Nguyen. 2020. Personalized Federated Learning with Moreau Envelopes. In 34th Conference on Neural Information Processing Systems (NeurIPS 2020), Vancouver, Canada.'
---

[[Paper](https://papers.nips.cc/paper/2020/hash/f4f1f13c8289ac1b1ee0ff176b56fc60-Abstract.html)] [[Code](https://github.com/CharlieDinh/pFedMe)]

Abstract: Federated learning (FL) is a decentralized and privacy-preserving machine learning technique in which a group of clients collaborate with a server to learn a global model without sharing clients' data. One challenge associated with FL is statistical diversity among clients, which restricts the global model from delivering good performance on each client's task. To address this, we propose an algorithm for personalized FL (pFedMe) using Moreau envelopes as clients' regularized loss functions, which help decouple personalized model optimization from the global model learning in a bi-level problem stylized for personalized FL. Theoretically, we show that pFedMe convergence rate is state-of-the-art: achieving quadratic speedup for strongly convex and sublinear speedup of order 2/3 for smooth nonconvex objectives. Experimentally, we verify that pFedMe excels at empirical performance compared with the vanilla FedAvg and Per-FedAvg, a meta-learning based personalized FL algorithm.