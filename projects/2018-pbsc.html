
<!doctype html>
<html>

<head>
<style>
.content { width: 960px; padding:20px; margin:auto }
</style>
</head>


<body>
<div  class = 'content'>
<h1 style="text-align:center;">Perception-based seam cutting for image stitching</h1>

<p style="text-align:center;">
Nan Li, <a href='https://tlliao.github.io'>Tianli Liao</a> and Chao Wang</p>


<figure>
<center>
<img src="./seam-cutting.jpg" alt="Framework of our algorithm" width="90%">
<figcaption>Framework of our algorithm.</figcaption>
</center>
</figure>

<!-- Quick links: <a href="#Paper">Paper</a> - <a href="#Source">Source codes</a> - <a href="#Datasets">Datasets</a> -->

<h2>Abstract</h2>

<p>
Image stitching is still challenging in consumer-level photography due to imperfect image captures. Recent works show that seam-cutting approaches can effectively relieve the artifacts generated by local misalignment. Normally, the seam-cutting approach is described in terms of energy minimization. However, few of existing methods consider the human perception in their energy functions, which sometimes causes that there exists another seam that is perceptually better than the one with the minimum energy. In this paper, we propose a novel perception-based seam-cutting approach that considers the nonlinearity and the nonuniformity of human perception into the energy minimization. Our method uses a sigmoid metric to characterize the perception of color discrimination and a saliency weight to simulate that the human eye inclines to pay more attention to the salient objects. In addition, our approach can be easily integrated into other stitching pipelines. Representative experiments demonstrate substantial improvements over the conventional seam-cutting approach.
</p>

<a name="Paper"></a>
<h2>Paper</h2>

<p>
<ul>
<li>Perception-based seam cutting for image stitching,<br />Nan Li, Tianli Liao and Chao Wang,<br />Signal, Image and Video Processing (SIViP), 12(5), 967-974, 2018.</li></ul></p>

<a name="Source"></a>
<h2>Source codes</h2>

<p>
<ul>
<li><a href='https://github.com/tlliao/Perception-based-seam-cutting'>Perception-based-seam-cutting</a><br />Given two input images, stitch them together into a seamless result.</li></ul>
*Kindly cite the above pape if using our code in your work.
</p>


<a name="Datasets"></a>
<h2>Datesets</h2>

<p>We experimented with our algorithm on images from the <a href='http://web.cecs.pdx.edu/~fliu/project/stitch/'>Parallax</a> and <a href='http://www.linkaimo.com/publications/ImageStitching/ImageStitching.html'>SEAGULL</a> datasets and our own stitching dataset. You can download the stitching <a href='https://tlliao.github.io/images/dataset-1.zip'>dataset</a> here.
</p>

<a name="Citation"></a>
<h2>BibTex</h2>

<p><cite>
@article{li2018perception,<br>  
  title={Perception-based seam cutting for image stitching},<br>  
  author={Li, Nan and Liao, Tianli and Wang, Chao},<br>  
  journal={Signal, Image and Video Processing},<br>  
  volume={12},<br>  
  number={5},<br>  
  pages={967--974},<br>  
  year={2018},<br> 
  publisher={Springer}<br>  
}  
</p></cite>

</div>
</body>
</html>
