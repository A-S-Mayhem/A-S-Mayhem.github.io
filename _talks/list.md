---
title: ""
collection: talks
type: "Talk"
permalink: /talks/list.md
---

**Tutorial:** <span style="color:blue">Preference Bandits.</span> *Asian Conference of Machine Learning (ACML)*, November 2021.

<span style="color:blue">PbRL: Preference based Reinforcement Learning.</span> *RL Track, Microsoft Research Summit*, October 2021.

<span style="color:blue">Adversarial Dueling Bandits.</span> *Data Science in India, KDD Conference, India*, August 2021.

<span style="color:blue">Battle of Bandits.</span> *Sabarmati Seminar Series, IIT Gandhinagar, India*, July 2021.

<span style="color:blue">Online Learning from Preferences.<\span> *SIERRA-Seminar, Inria, Paris", January 2020.

<span style="color:blue">Structured Battling Bandits.<\span> *Microsoft Research, Bangalore, India*. October 2019.

\item[] \emph{``Online Learning from Preference Data"}, {\color{blue} EECS department, University of Michigan, Ann Arbor, Michgan, USA}, September 2019.

\item[] \emph{``Information Aggregation from Sequential Preferences"}, *Computer Science department, Stanford University, Serra Mall, Stanford, California, USA*. August 2019.

<span style="color:blue">Active Ranking with Subset-wise Preferences.<\span> *22nd International Conference on Artificial Intelligence and Statistics (AISTATS)*. Naha, Okinawa, Japan, April 2019.

<span style="color:blue">PhD Thesis Overview: Information Aggregation from Preferential Feedback.<\span> *EECS Symposium, Indian Institute of Science, Bangalore, India*. April 2019.

<span style="color:blue">PAC Battling-Bandits in the Plackett-Luce model.<\span> *30th International Conference on Algorithmic Learning Theory (ALT), 2019*. Chicago, USA, March 2019.
