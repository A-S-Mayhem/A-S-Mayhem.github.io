---
title: ""
collection: talks
type: "Talk"
permalink: /talks/list.md
---

<ul>
                <li>For Geeks</li>
                <li>GeeksforGeeks</li>
                <li>A Computer Science Poratal</li>
            </ul>

**Tutorials:** <br/>
 &ensp;&ensp;<span style="color:blue">Preference Bandits.</span> Asian Conference of Machine Learning (ACML). November 2021.<br/>
 &ensp;&ensp;<span style="color:blue">Bandits for Beginners.</span> Microsoft Reactor: Data Science and Machine Learning Track. November 2021.<br/>
<br/>
 **Talks:** <br/>
&ensp;&ensp;<span style="color:blue">PbRL: Preference based Reinforcement Learning.</span> RL Track, Microsoft Research Summit. October 2021.<br/>
&ensp;&ensp;<span style="color:blue">Adversarial Dueling Bandits.</span> Data Science in India, KDD Conference, India. August 2021.<br/>
&ensp;&ensp;<span style="color:blue">Battle of Bandits.</span> Sabarmati Seminar Series, IIT Gandhinagar, India. July 2021.<br/>
&ensp;&ensp;<span style="color:blue">Online Learning from Preferences.</span> SIERRA-Seminar, Inria, Paris. January 2020.<br/>
&ensp;&ensp;<span style="color:blue">Structured Battling Bandits.</span> Microsoft Research, Bangalore, India. October 2019.<br/>

<!-- 
*3 talks at ICML*, 2021. <br/><br/>
<span style="color:blue">Active Ranking with Subset-wise Preferences.</span> *Artificial Intelligence and Statistics (AISTATS)*. Naha, Okinawa, Japan, April 2019.<br/><br/>
<span style="color:blue">PhD Thesis Overview: Information Aggregation from Preferential Feedback.</span> *EECS Symposium, Indian Institute of Science, Bangalore, India*. April 2019.<br/><br/>
<span style="color:blue">PAC Battling-Bandits in the Plackett-Luce model.</span> *Algorithmic Learning Theory (ALT), 2019*. Chicago, USA, March 2019.<br/> 
-->
