
<!DOCTYPE html>
<html>



<body>
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                Hand Gestures Recognition in Videos   <br>
                Taken with Lensless Camera</br>
                <small>
                    Optics Express
                </small>
            </h2>

        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>                        
                        Yinger Zhang    
                    </li>
                    <li>
                        Zhouyi Wu
                    </li>
                    <li>
                        Peiying Lin
                    </li>
                    <li>
                        Jiangtao Huangfu
                    </li>
                </ul>
            </div>
        </div>


        <div class="row">
            <div class="col-md-6 col-md-offset-3 text-center">
                <ul class="nav nav-pills nav-justified">
                    <li>
                        <a href="https://opg.optica.org/oe/fulltext.cfm?uri=oe-30-22-39520&id=509832">
                            
                            <h4><strong>Paper</strong></h4>
                        </a>
                    </li>



                </ul>
            </div>
        </div>



        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Abstract
                </h3>
                <image src="image/pro_hand_framework.png" class="img-responsive" alt="overview"><br>
                    <p class="text-justify">
                        A lensless camera is an imaging system that uses a mask in place of a lens, making it thinner, lighter, and less expensive than a lensed camera. However, additional complex computation and time are required for image reconstruction. This work proposes a deep learning model named Raw3dNet that recognizes hand gestures directly on raw videos captured by a lensless camera without the need for image restoration. In addition to conserving computational resources, the reconstruction-free method provides privacy protection. Raw3dNet is a novel end-to-end deep neural network model for the recognition of hand gestures in lensless imaging systems. It is created specifically for raw video captured by a lensless camera and has the ability to properly extract and combine temporal and spatial features. The network is composed of two stages: 1. spatial feature extractor (SFE), which enhances the spatial features of each frame prior to temporal convolution; 2. 3D-ResNet, which implements spatial and temporal convolution of video streams. The proposed model achieves 98.59% accuracy on the Cambridge Hand Gesture dataset in the lensless optical experiment, which is comparable to the lensed-camera result. Additionally, the feasibility of physical object recognition is assessed. Furtherly, we show that the recognition can be achieved with respectable accuracy using only a tiny portion of the original raw data, indicating the potential for reducing data traffic in cloud computing scenarios.
                        <br>
                    </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Dataset
                </h3>
                

                <p align="center">
                <image class="center" src="image/pro_hand_hardware.jpg"   width="400"  alt="overview" /><br>
                </br><image class="center" src="image/pro_hand_dataset.png"   width="600"  alt="overview" /><br>
                </p>
                   
            </div>
        </div>


        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Method
                </h3>

                <br> <b>Reconstruction results from ADMM and CRNN</b>

                <p align="center">
                </br><image class="center" src="image/pro_hand_model.png" width="700"  alt="admm&cnn" /><br>
                </p>
               
            </div>
        </div>

        <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Result
                </h3>

                <br> <b>Definition of datasets</b>

                <p align="center">
                </br><image class="center" src="image/pro_hand_reconstruct.png" width="700"  alt="admm&cnn" /><br>
                </p>

                <b> Comparison of performances for 3D-ResNet/ Raw3dNet for lensless video; 
                    comparison for lensless video/reconstruction video/lensed video </b>

                <p align="center">
                </br><image class="center" src="image/pro_hand_compare1.PNG" width="700"  alt="admm&cnn" /><br>
                </p>

                <b> Assessment for various down-sampling techniques and ratios</b>
                <p align="center">
                </br><image class="center" src="image/pro_hand_compare2.PNG" width="700"  alt="admm&cnn" /><br>
                </p>
                
            </div>
        </div>

        

        

       






    <!-- <div class="row">
            <div class="col-md-8 col-md-offset-2">
                <h3>
                    Key Contributions
                </h3>
                <br />
                <ul>
                    <li>We propose an efficient implementation for the learnable intermediate stage of a general
                        lensless model. In our <a href=https://siddiquesalman.github.io/flatcam_iccv.html>prior
                            work</a>, we shown this for the separable lensless model. Here
                        we non-trivially extend it to the general lensless case.</li>

                    <figure>
                        <image src="img/fig_7_sim.jpg" class="img-responsive" alt="overview">
                            <figcaption><b>Some simulated outputs.</b> Notice how closely the simulated measurements
                                resemble real ones.
                            </figcaption>
                    </figure>

                    <li>We verify the robustness of the proposed learnable intermediate mapping for the non-separable
                        lensless model on challenging scenarios where the lensless system does not follow a full
                        convolutional assumption.</li>

                    <li>We propose an initialization scheme for the non- separable lensless model that doesnâ€™t require
                        explicit PSF calibration.</li>

                    <li>Similar to the display and direct captured measurements collected using the separable mask
                        <i><a href=https://intra.ece.ucr.edu/~sasif/papers/2015_AASVR_flatcam_iccv.pdf>FlatCam</a></i>
                        and described in our <a href=https://siddiquesalman.github.io/flatcam_iccv.html>previous
                            work</a>, we collect corresponding datasets for the
                        non-separable mask <i><a href=https://ieeexplore.ieee.org/document/9076617>PhlatCam</a></i>.
                    </li>

                    <br>

                    <figure>
                        <image src="img/dataset3.jpg" class="img-responsive" alt="overview">
                            <figcaption><b><br>Some simulated outputs.</b> Notice how closely the simulated measurements
                                resemble real ones.
                            </figcaption>
                    </figure>

                    <li>We also collect a dataset of unconstrained indoor lensless measurements paired with
                        corresponding unaligned webcam images which is finally used to finetune our proposed
                        <b>FlatNet</b> to
                        robustly deal with unconstrained real-world scenes.</li>

                    <li>Our method outperforms previous traditional and deep learning based lensless reconstruction
                        methods.</li>
                </ul>
            </div>
        </div> -->




</body>

</html>
