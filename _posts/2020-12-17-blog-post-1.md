---
title: 'Paper Reivew: Offline reinforcement learning: Tutorial, review, and perspectives on open problems'
date: 2020-12-15
permalink: /_posts/2020/11/23/blog-post-1/ 
tags:
  - study
  - research
  - offline reinforcement learning
---
 
>  This blog reviews a review paper of offline reinforcement learning and collects the related papers.

## What is offline reinforcement learning algorithms

1. Reinforcement learning algorithms that utilize previously collected data, **without additional online data collection**.
2. The training process does not interact with MDP at all, and the policy is only deployed after being trained. 

## Why to use offline reinforcement learning algorithms   

1. The process of reinforcement learning involves iteratively collecting experience by interacting with the environment, typically with the latest learned policy, and then using that experience to improve the policy. 
In many settings, this sort of online interaction is impractical, either because data collection is expensive (e.g., in robotics, educational agents, or healthcare) and dangerous (e.g., in autonomous driving, or healthcare).

## Challenges in offline reinforcement learning algorithms

1. Learning from entire offline data, without any additional on-policy interaction is ineffective. High-dimensionalHigh-dimensional and expressive function approximation generally exacerbates this issue, since function approximation leaves the algorithms vulnerable to distributional shift.

## How to achieve offline reinforcement learning algorithms  