---
title: 'Inspiring graph deep learning models'
date: 2020-12-15
permalink: /_posts/2020/11/23/blog-post-1/ 
tags:
  - study
  - research
---

>  This blog reviews some inspirng and impressive graph deep learning models.


1. [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/abs/1505.04597)
    * The feature extraction process includes: (1)direct mapping; (2)direct mapping after convolution; (3)convolution and deconvolution.
    
    
2. [Graph U-Nets](http://proceedings.mlr.press/v97/gao19a/gao19a.pdf)
    * Similar architecture with U-Net.
    * Design graph pooling and unpooling operations based on learnable top-k node selection module built with neural network.
    * [code](https://github.com/HongyangGao/Graph-U-Nets)
    
3. [Self-Attention Graph Pooling](https://arxiv.org/pdf/1904.08082.pdf)
    * Self-attention, commonly referred to as intra-attention, allows input features to be the criteria for the attention itself.
    * The self-attention mechanism is exploited to distinguish between the nodes that should be dropped and the nodes that should be retained.
    * The attention score is calculated based on graph convolution.
    * [code](https://github.com/inyeoplee77/SAGPool)
    
4. [Graph Attention Networks](https://arxiv.org/pdf/1710.10903.pdf)
    * [code](https://github.com/Diego999/pyGAT)

5. [Representation learning on graphs with jumping knowledge networks](https://arxiv.org/pdf/1806.03536.pdf)

6. [Hierarchical graph representation learning with differentiable pooling](https://arxiv.org/pdf/1806.08804.pdf%20http://arxiv.org/abs/1806.08804.pdf)

7. [Haar Graph Pooling](http://proceedings.mlr.press/v119/wang20m/wang20m.pdf)