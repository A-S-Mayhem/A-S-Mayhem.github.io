pub_date	title	venue	excerpt	citation	url_slug	paper_url
2021-08-01	Detecting Harmful Memes and Their Targets	ACL’21 (Findings)	"This study explores the use of internet memes in social media, particularly their rise in conveying political and socio-cultural opinions. Harmful memes, often complex and satirical, have become a concern. The study introduces two tasks: detecting harmful memes and identifying their target (individual, organization, etc.). We present HarMeme, a dataset with COVID-19-related memes, and emphasize the importance of multimodal models for these tasks while acknowledging existing limitations and the need for more research."	"Shraman Pramanick, Dimitar Dimitrov, Rituparna Mukherjee, Shivam Sharma, Md. Shad Akhtar, Preslav Nakov, and Tanmoy Chakraborty. 2021. Detecting Harmful Memes and Their Targets. In <i>Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</I>, pages 2783–2796, Online. Association for Computational Linguistics."	acl21-harmfulness-detection	https://aclanthology.org/2021.findings-acl.246/
2021-11-01	MOMENTA: A Multimodal Framework for Detecting Harmful Memes and Their Targets	EMNLP’21 (Findings)	"Internet memes are powerful for communication, but harmful ones are rising, posing detection challenges. The study introduces MOMENTA, a neural network to detect harmful memes and identify their targets in a multimodal context. MOMENTA outperforms rivals, providing interpretability and generalizability."	"Shraman Pramanick, Shivam Sharma, Dimitar Dimitrov, Md. Shad Akhtar, Preslav Nakov, and Tanmoy Chakraborty. 2021. MOMENTA: A Multimodal Framework for Detecting Harmful Memes and Their Targets. In <i>Findings of the Association for Computational Linguistics: EMNLP 2021<i>, pages 4439–4455, Punta Cana, Dominican Republic. Association for Computational Linguistics."	emnlp21-momenta-detection	https://aclanthology.org/2021.findings-emnlp.379/
2022-05-01	"Findings of the CONSTRAINT 2022 Shared Task on Detecting the Hero, the Villain, and the Victim in Memes"	"Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situations (CONSTRAINT22), ACL’22"	"The CONSTRAINT 2022 Workshop shared task focused on understanding harmful memes by labeling the roles of entities within them as hero, villain, victim, or none. We curated the HVVMemes dataset, containing 7000 memes related to COVID-19 and US Politics. Despite attracting 105 participants, only 6 submissions were made, with the top submission achieving an F1-score of 58.67."	"Shivam Sharma, Tharun Suresh, Atharva Kulkarni, Himanshi Mathur, Preslav Nakov, Md. Shad Akhtar, and Tanmoy Chakraborty. 2022. Findings of the CONSTRAINT 2022 Shared Task on Detecting the Hero, the Villain, and the Victim in Memes. In <i>Proceedings of the Workshop on Combating Online Hostile Posts in Regional Languages during Emergency Situations</i>, pages 1–11, Dublin, Ireland. Association for Computational Linguistics."	acl22-hvv-findings	https://aclanthology.org/2022.constraint-1.1
2022-07-01	DISARM: Detecting the Victims Targeted by Harmful Memes	NAACL’22 (Findings)	"This paper addresses the misuse of internet memes for harmful purposes, particularly targeting individuals, communities, or society. We introduce DISARM, a framework that detects and classifies harmful meme targets using deep neural networks. DISARM outperforms other systems, reducing harmful target identification errors by up to 9%."	"Shivam Sharma, Md Shad Akhtar, Preslav Nakov, and Tanmoy Chakraborty. 2022. DISARM: Detecting the Victims Targeted by Harmful Memes. In <i>Findings of the Association for Computational Linguistics: NAACL 2022</i>, pages 1572–1588, Seattle, United States. Association for Computational Linguistics."	naacl23-disarm-target	https://aclanthology.org/2022.findings-naacl.118
2022-07-01	Detecting and Understanding Harmful Memes: A Survey	IJCAI’22 (Survey)	"The paper addresses the challenge of identifying harmful online content, specifically harmful memes that often mix text, visuals, and audio. It introduces a new typology for harmful memes and highlights gaps in research, like the lack of suitable datasets for some types of harmful memes. The study also discusses challenges in understanding multimodal content and the need for further research in this area."	"Sharma, Shivam and Alam, Firoj and Akhtar, Md. Shad and Dimitrov, Dimitar and Da San Martino, Giovanni and Firooz, Hamed and Halevy, Alon and Silvestri, Fabrizio and Nakov, Preslav and Chakraborty, Tanmoy. (2015). ""Detecting and Understanding Harmful Memes: A Survey.” <i>Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI-22</i>."	ijcai22-survey-harmfulness	https://doi.org/10.24963/ijcai.2022/781
2022-11-01	Domain-aware Self-supervised Pre-training for Label-Efficient Meme Analysis	AACL’22 (Main)	"The paper presents two self-supervised pre-training methods, Ext-PIE-Net and MM-SimCLR, for multi-modal tasks like meme analysis. These methods use specialized pretext tasks and outperform fully supervised approaches in various meme-related tasks, demonstrating their generalizability and the importance of better multi-modal self-supervision methods."	"Shivam Sharma, Mohd Khizir Siddiqui, Md. Shad Akhtar, and Tanmoy Chakraborty. 2022. Domain-aware Self-supervised Pre-training for Label-Efficient Meme Analysis. In <i>Proceedings of the 2nd Conference of the Asia-Pacific Chapter of the Association for Computational Linguistics and the 12th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</I>, pages 792–805, Online only. Association for Computational Linguistics."	aacl22-ssl-memes	https://aclanthology.org/2022.aacl-main.60
2023-05-01	"Characterizing the Entities in Harmful Memes: Who is the Hero, the Villain, the Victim?"	EACL’22 (Main)	"The paper discusses the importance of understanding the intent and potential harm associated with viral memes. It focuses on identifying the roles of entities within memes, such as 'hero,' 'villain,' or 'victim.' The study introduces a multi-modal framework called VECTOR for this task, which outperforms standard models. The research also highlights challenges in semantically labeling roles within memes and provides comparative analyses."	"Shivam Sharma, Atharva Kulkarni, Tharun Suresh, Himanshi Mathur, Preslav Nakov, Md. Shad Akhtar, and Tanmoy Chakraborty. 2023. Characterizing the Entities in Harmful Memes: Who is the Hero, the Villain, the Victim?. In <i>Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics</i>, pages 2149–2163, Dubrovnik, Croatia. Association for Computational Linguistics."	eacl23-vector-hvv	https://aclanthology.org/2023.eacl-main.157
2023-06-26	What Do You MEME? Generating Explanations for Visual Semantic Role Labelling in Memes	AAAI’23 (Main)	"The paper discusses the importance of memes in social media marketing and introduces a task called EXCLAIM, which generates explanations for semantic roles in memes. We create a dataset, ExHVV, and a multi-task learning framework called LUMEN, which outperforms baselines in natural language generation. The study shows that cues for semantic roles in memes also help generate explanations effectively."	"Sharma, S., Agarwal, S., Suresh, T., Nakov, P., Akhtar, M. S., & Chakraborty, T. (2023). What Do You MEME? Generating Explanations for Visual Semantic Role Labelling in Memes. <i>Proceedings of the AAAI Conference on Artificial Intelligence</I>, 37(8), 9763-9771. https://doi.org/10.1609/aaai.v37i8.26166"	Ijcai23-lumen-explanation	https://doi.org/10.1609/aaai.v37i8.26166
2023-06-01	MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization	ACL’23 (Main)	"The paper discusses the challenge of understanding the context of memes and introduces the MEMEX task. We create a dataset called MCC and propose a multimodal neural framework called MIME, which outperforms other models by 4% in F1-score. The study also provides detailed performance analyses and insights into cross-modal contextual associations."	"Shivam Sharma, Ramaneswaran S, Udit Arora, Md. Shad Akhtar, and Tanmoy Chakraborty. 2023. MEMEX: Detecting Explanatory Evidence for Memes via Knowledge-Enriched Contextualization. In <i>Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)</i>, pages 5272–5290, Toronto, Canada. Association for Computational Linguistics."	acl23-evidence-memes	https://aclanthology.org/2023.acl-long.289